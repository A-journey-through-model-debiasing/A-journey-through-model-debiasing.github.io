{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "6e60fdb0",
      "metadata": {
        "id": "6e60fdb0"
      },
      "source": [
        "# **A Journey through model debiasing: from methods to applications**\n",
        "### *Tutorial @ICIAP2025 - Rome*\n",
        "\n",
        "#### **Hands on - Model Debiasing**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4d54df9",
      "metadata": {
        "id": "d4d54df9"
      },
      "source": [
        "##### **First Part: synthetic benchmarks**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54be925f",
      "metadata": {
        "id": "54be925f"
      },
      "source": [
        "In this guided tutorial, we will explore some basic implementation of debiasing techniques that can generally applied in Computer Vision and Deep Learning tasks.  \n",
        "This tutorial will be based on a Work-In-Progress repository that we are customizing starting from the work of [1]. All the basic requirements for datasets logic implementations and methods training procedures will be provided, and we will ask you to fill in some code sections so that you can have a proper hands-on experience.\n",
        "\n",
        "First, we will utilize one of the most used synthethic benchmarks for Model Debiasing in Image Classification, Colored MNIST [2]. In the first task we will consider the bias annotations available, and we will compare the behavior of a vanilla ERM model with a basic debiasing routine where we just upweight and upsample bias-conflicting training samples.\n",
        "\n",
        "Next, we will move to the *unsupervised debiasing* setting, where bias annotations are not known. Here, we will ask you to complete the implementation of \"Learning from Failure\" [2], which is a well established end-to-end debiasing method."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0170c0b9",
      "metadata": {
        "id": "0170c0b9"
      },
      "source": [
        "#### Hands-On"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As a first thing, we will clone the repository containing all the necessary code for completing this tutorial. Just run the following cell containing the required commands."
      ],
      "metadata": {
        "id": "R7vJgdbt0iyP"
      },
      "id": "R7vJgdbt0iyP"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "249695da",
      "metadata": {
        "id": "249695da"
      },
      "outputs": [],
      "source": [
        "!rm -rf JTMD\n",
        "!git clone https://github.com/ResonantFilter/JTMD.git"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A few basic imports, alongside a utility class that will come in hand later. (Basically, it fakes the usage of command line arguments and ArgumentParser)"
      ],
      "metadata": {
        "id": "tEhMgNcd0pQ9"
      },
      "id": "tEhMgNcd0pQ9"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils import data\n",
        "from torchvision import transforms\n",
        "import os\n",
        "\n",
        "class DotDict(dict):\n",
        "    \"\"\"\n",
        "    A dictionary that allows accessing entries with dot notation.\n",
        "    \"\"\"\n",
        "    def __getattr__(self, name):\n",
        "        try:\n",
        "            return self[name]\n",
        "        except KeyError:\n",
        "            raise AttributeError(f\"'{self.__class__.__name__}' object has no attribute '{name}'\")\n",
        "\n",
        "    def __setattr__(self, name, value):\n",
        "        self[name] = value\n",
        "\n",
        "    def __delattr__(self, name):\n",
        "        try:\n",
        "            del self[name]\n",
        "        except KeyError:\n",
        "            raise AttributeError(f\"'{self.__class__.__name__}' object has no attribute '{name}'\")\n",
        "\n",
        "# Example usage:\n",
        "# config_dict = {'learning_rate': 0.001, 'batch_size': 32}\n",
        "# config = DotDict(config_dict)\n",
        "# print(config.learning_rate)\n",
        "# config.epochs = 10\n",
        "# print(config['epochs'])"
      ],
      "metadata": {
        "id": "7pW9AVjTrUDI"
      },
      "id": "7pW9AVjTrUDI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can start importing components from the repository. We'll start by importing the Colored MNIST dataset logic implementation, a utility function for showing some dataset samples, and a basic trainer for standard ERM training."
      ],
      "metadata": {
        "id": "1RdGUUd60-LB"
      },
      "id": "1RdGUUd60-LB"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from typing import Literal\n",
        "\n",
        "\n",
        "\n",
        "def show_bias_image_grid(\n",
        "    dataset: Dataset,\n",
        "    num_classes_to_show: int,\n",
        "    bias_logic: Literal['class_equals_bias', 'bias_is_zero'] = 'class_equals_bias'\n",
        "):\n",
        "    print(f\"Searching for samples with bias logic: '{bias_logic}'...\")\n",
        "\n",
        "\n",
        "    found_samples = {i: {\"aligned\": None, \"conflicting\": None} for i in range(num_classes_to_show)}\n",
        "\n",
        "    num_slots_to_fill = num_classes_to_show * 2\n",
        "    filled_slots = 0\n",
        "\n",
        "\n",
        "    for image, (class_label, bias_label), _ in dataset:\n",
        "        class_label = class_label.item()\n",
        "        bias_label = bias_label.item()\n",
        "\n",
        "        if filled_slots >= num_slots_to_fill:\n",
        "            break\n",
        "\n",
        "        if class_label < num_classes_to_show:\n",
        "\n",
        "            is_aligned = False\n",
        "            if bias_logic == 'class_equals_bias':\n",
        "                is_aligned = (class_label == bias_label)\n",
        "            elif bias_logic == 'bias_is_zero':\n",
        "                is_aligned = (bias_label == 0)\n",
        "\n",
        "            sample_type = \"aligned\" if is_aligned else \"conflicting\"\n",
        "\n",
        "\n",
        "            if found_samples[class_label][sample_type] is None:\n",
        "                found_samples[class_label][sample_type] = image\n",
        "                filled_slots += 1\n",
        "\n",
        "    image_grid_list = []\n",
        "    placeholder_image = torch.zeros_like(dataset[0][0]) # A black image as placeholder\n",
        "\n",
        "    for i in range(num_classes_to_show):\n",
        "        aligned_img = found_samples[i]['aligned']\n",
        "        conflicting_img = found_samples[i]['conflicting']\n",
        "\n",
        "        image_grid_list.append(aligned_img if aligned_img is not None else placeholder_image)\n",
        "        image_grid_list.append(conflicting_img if conflicting_img is not None else placeholder_image)\n",
        "\n",
        "    grid = torchvision.utils.make_grid(image_grid_list, nrow=2, padding=4)\n",
        "\n",
        "    plt.figure(figsize=(8, num_classes_to_show * 2))\n",
        "    np_grid = grid.permute(1, 2, 0).numpy()\n",
        "\n",
        "    plt.imshow(np_grid)\n",
        "    plt.title(f\"Image Grid (Bias Logic: {bias_logic})\", fontsize=16)\n",
        "    plt.axis('off')\n",
        "\n",
        "    ax = plt.gca()\n",
        "\n",
        "    img_size = placeholder_image.shape[2]\n",
        "    padding = 4\n",
        "\n",
        "    ax.text((img_size + padding)/2, -10, 'Bias-Aligned', ha='center', va='bottom', fontsize=12)\n",
        "    ax.text(img_size + padding + (img_size + padding)/2, -10, 'Bias-Conflicting', ha='center', va='bottom', fontsize=12)\n",
        "\n",
        "    for i in range(num_classes_to_show):\n",
        "        y_pos = i * (img_size + padding) + (img_size / 2)\n",
        "        ax.text(-20, y_pos, f\"Class {i}\", ha='right', va='center', fontsize=12, rotation=0)\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "kRUoPUtrV8Yu"
      },
      "id": "kRUoPUtrV8Yu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from JTMD.datasets.CMNIST import CMNIST\n",
        "train_set = CMNIST(root=\"data/cmnist\", env=\"train\", bias_amount=95, transform=transforms.ToTensor())\n",
        "\n",
        "show_bias_image_grid(train_set, 10, bias_logic=\"class_equals_bias\")"
      ],
      "metadata": {
        "id": "DumW-HVjSz9F"
      },
      "id": "DumW-HVjSz9F",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we can import the baseline ERM trainer, and set up the required parameter configuration for running the experiment."
      ],
      "metadata": {
        "id": "Y9440T73Xsx-"
      },
      "id": "Y9440T73Xsx-"
    },
    {
      "cell_type": "code",
      "source": [
        "from JTMD.methods.erm import ERMTrainer\n",
        "\n",
        "config = DotDict()\n",
        "config[\"dataset\"] = \"cmnist\"\n",
        "config[\"arch\"] = \"mlp\"\n",
        "config[\"pretrain\"] = \"none\"\n",
        "config[\"optimizer\"] = \"adam\"\n",
        "config[\"lr\"] = 1e-04\n",
        "config[\"batch_size\"] = 256\n",
        "config[\"epoch\"] = 20\n",
        "config[\"weight_decay\"] = 0.0\n",
        "config[\"amp\"] = False\n",
        "config[\"start_seed\"] = 0\n",
        "config[\"rho\"] = 95\n",
        "config[\"run_name\"] = \"cmnist_erm\"\n",
        "config[\"exp_root\"] = config[\"run_name\"]\n",
        "config[\"reweight_groups\"] = False\n",
        "config[\"reweight_classes\"] = False\n",
        "config[\"seed\"] = 0\n",
        "config[\"num_workers\"] = 2\n",
        "config[\"pin_memory\"] = False\n",
        "config[\"wandb\"] = False\n",
        "\n",
        "os.makedirs(f\"logs/{config['exp_root']}\", exist_ok = True)"
      ],
      "metadata": {
        "id": "9k8VPfGPDCCE"
      },
      "id": "9k8VPfGPDCCE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we have a snippet showing the core training logic of the ERM training.\n",
        "\n",
        "\n",
        "```python\n",
        "class ERMTrainer(BaseTrainer):\n",
        "    def _setup_method_name_and_default_name(self):\n",
        "        args = self.args\n",
        "        args.method = \"erm\"\n",
        "        default_name = f\"{args.method}_{args.dataset}\"\n",
        "        self.default_name = default_name\n",
        "\n",
        "    def train(self):\n",
        "        args = self.args\n",
        "        self._set_train()\n",
        "        samples_loss_fn = torch.nn.CrossEntropyLoss(reduction=\"none\")\n",
        "        losses = AverageMeter()\n",
        "        meter = SubgroupMetricsTracker(\n",
        "            num_classes=self.num_classes,\n",
        "            num_groups=self.num_groups,\n",
        "            device=self.device,\n",
        "            log_history=True,\n",
        "            wandb_logger = wandb if self.args.wandb else None,\n",
        "            prefix=\"tr\"\n",
        "        )\n",
        "\n",
        "        pbar = tqdm(self.train_loader, dynamic_ncols=True)\n",
        "        for batch, (dat, labels, _) in enumerate(pbar):\n",
        "            image, target = dat, labels\n",
        "            obj_gt = target[0]  \n",
        "            group_gt = labels[1]\n",
        "            image = image.to(self.device)\n",
        "            obj_gt = obj_gt.to(self.device)\n",
        "            group_gt = group_gt.to(self.device)\n",
        "\n",
        "            with torch.amp.autocast(\"cuda\", enabled=args.amp):\n",
        "                output = self.classifier(image)\n",
        "                loss = self.criterion(output, obj_gt)\n",
        "\n",
        "            self._loss_backward(loss)\n",
        "            self._optimizer_step(self.optimizer)\n",
        "            self._scaler_update()\n",
        "            self.optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "            accs = meter.compute_accuracy(output, obj_gt)\n",
        "            losses = meter.compute_loss(output, obj_gt, samples_loss_fn)\n",
        "            meter.update(losses, accs, obj_gt, group_gt)\n",
        "\n",
        "            pbar.set_description(\n",
        "                f\"[{self.cur_epoch}/{args.epoch}] loss: {meter.loss_avg.avg():.4f}\"\n",
        "            )\n",
        "            meter.log_epoch(self.cur_epoch, aligned_topology=\"diagonal\")\n",
        "```"
      ],
      "metadata": {
        "id": "nU7N7elcWfY1"
      },
      "id": "nU7N7elcWfY1"
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a classical training loop for ERM learning in PyTorch, plus some code for handling datasets with bias annotations. This is already implemented for you, so you can launch a training by running the following cell."
      ],
      "metadata": {
        "id": "mku8_zUqXJWR"
      },
      "id": "mku8_zUqXJWR"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2c36708"
      },
      "source": [
        "trainer = ERMTrainer(config)\n",
        "trainer()"
      ],
      "id": "f2c36708",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "With the following cell, you can evaluate your model and get a visual evaluation of the model performance across each target class and subgroup."
      ],
      "metadata": {
        "id": "MDW7Z0OPYCX_"
      },
      "id": "MDW7Z0OPYCX_"
    },
    {
      "cell_type": "code",
      "source": [
        "from JTMD.erm_training import evaluate_model\n",
        "\n",
        "_, performance_meter = evaluate_model(\n",
        "    trainer.classifier,\n",
        "    trainer.test_loader,\n",
        "    trainer.num_classes,\n",
        "    trainer.num_groups,\n",
        "    trainer.criterion,\n",
        "    config[\"epoch\"],\n",
        "    device=trainer.device,\n",
        "    wb=None,\n",
        "    prefix=\"test\",\n",
        "    config=config\n",
        ")\n",
        "\n",
        "performance_meter.plot_subgroup_metrics(show=True, fontsize=7, figsize=(12, 7))"
      ],
      "metadata": {
        "id": "4WcyFZok8lrG"
      },
      "id": "4WcyFZok8lrG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will see a simple Supervised Approach where we basically upsample bias-conflcting samples by using a WeightedRandomSampler for sampling mini-batches. Moreover, we upweight the loss of bias-conflicting samples and downweight the loss coming from bias-aligned samples. This is possible only when bias annotations are fully available.  \n",
        "\n",
        "This time, we will ask you to fill in the implementation of a train_loader where mini-batches are sampled so that each subgroup is equally represented in each batch."
      ],
      "metadata": {
        "id": "Jjwk7hVtYBLw"
      },
      "id": "Jjwk7hVtYBLw"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "import wandb\n",
        "from tqdm import tqdm\n",
        "from torch.utils import data\n",
        "from JTMD.methods.base_trainer import BaseTrainer\n",
        "from JTMD.utils.advanced_metrics import AverageMeter, SubgroupMetricsTracker\n",
        "\n",
        "\n",
        "class NaiveSupervisedTrainer(BaseTrainer):\n",
        "    def __init__(self, args, **kwargs):\n",
        "        super().__init__(args, **kwargs)\n",
        "        self._setup_all()\n",
        "        self.set_train_loader(self.args)\n",
        "\n",
        "    def set_train_loader(self, config):\n",
        "        group_counts: torch.Tensor = (\n",
        "            (torch.arange(self.num_groups * self.num_classes).unsqueeze(1) == self.train_set.group_array)\n",
        "            .sum(1)\n",
        "            .float()\n",
        "        ) # Fast way of counting members of each subgroup\n",
        "        # Note that we used self.train_set.group_array, a tensor containing the group identifier\n",
        "        # of each sample\n",
        "\n",
        "        group_weights = # Fill here\n",
        "        weights = # Fill here\n",
        "        sampler = data.WeightedRandomSampler(\n",
        "            # Fill here\n",
        "            num_samples=len(self.train_set),\n",
        "            replacement=True\n",
        "        )\n",
        "\n",
        "        train_loader = data.DataLoader(\n",
        "            self.train_set,\n",
        "            batch_size=config.batch_size,\n",
        "            sampler= # Fill here\n",
        "            shuffle= # Fill here\n",
        "            num_workers=config.num_workers\n",
        "        )\n",
        "\n",
        "        self.train_loader = train_loader\n",
        "\n",
        "    def _setup_method_name_and_default_name(self):\n",
        "        args = self.args\n",
        "        args.method = \"naivesupervised\"\n",
        "        default_name = f\"{args.method}_{args.dataset}\"\n",
        "        self.default_name = default_name\n",
        "        args.reweight_groups = True\n",
        "        self.uw_factor = args.uw_factor\n",
        "        self.dw_factor = args.dw_factor\n",
        "\n",
        "    def _setup_criterion(self):\n",
        "        self.criterion = torch.nn.CrossEntropyLoss(reduction=\"none\")\n",
        "\n",
        "    def train(self):\n",
        "        args = self.args\n",
        "        self._set_train()\n",
        "        samples_loss_fn = torch.nn.CrossEntropyLoss(reduction=\"none\")\n",
        "        losses = AverageMeter()\n",
        "        meter = SubgroupMetricsTracker(\n",
        "            num_classes=self.num_classes,\n",
        "            num_groups=self.num_groups,\n",
        "            device=self.device,\n",
        "            log_history=True,\n",
        "            wandb_logger = wandb if self.args.wandb else None,\n",
        "            prefix=\"tr\"\n",
        "        )\n",
        "\n",
        "        pbar = tqdm(self.train_loader, dynamic_ncols=True)\n",
        "        for batch, (dat, labels, _) in enumerate(pbar):\n",
        "            image, target = dat, labels\n",
        "            obj_gt = target[0]\n",
        "            group_gt = labels[1]\n",
        "            image = image.to(self.device)\n",
        "            obj_gt = obj_gt.to(self.device)\n",
        "            group_gt = group_gt.to(self.device)\n",
        "\n",
        "            with torch.amp.autocast(\"cuda\", enabled=args.amp):\n",
        "                output = self.classifier(image)\n",
        "                loss = self.criterion(output, obj_gt)\n",
        "\n",
        "                # Put here the code to up/downweight samples\n",
        "                # You can use both gt labels to do so.\n",
        "\n",
        "\n",
        "                # Fill here\n",
        "\n",
        "\n",
        "                loss = loss.mean()\n",
        "\n",
        "            self._loss_backward(loss)\n",
        "            self._optimizer_step(self.optimizer)\n",
        "            self._scaler_update()\n",
        "            self.optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "            accs = meter.compute_accuracy(output, obj_gt)\n",
        "            losses = meter.compute_loss(output, obj_gt, samples_loss_fn)\n",
        "            meter.update(losses, accs, obj_gt, group_gt)\n",
        "\n",
        "            pbar.set_description(\n",
        "                f\"[{self.cur_epoch}/{args.epoch}] loss: {meter.loss_avg.avg():.4f}\"\n",
        "            )\n",
        "            meter.log_epoch(self.cur_epoch, aligned_topology=\"diagonal\")"
      ],
      "metadata": {
        "id": "D2ncYFCjtsff"
      },
      "id": "D2ncYFCjtsff",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = DotDict()\n",
        "config[\"dataset\"] = \"cmnist\"\n",
        "config[\"arch\"] = \"mlp\"\n",
        "config[\"pretrain\"] = \"none\"\n",
        "config[\"optimizer\"] = \"adam\"\n",
        "config[\"lr\"] = 1e-04\n",
        "config[\"batch_size\"] = 256\n",
        "config[\"epoch\"] = 20\n",
        "config[\"weight_decay\"] = 0.0\n",
        "config[\"amp\"] = False\n",
        "config[\"start_seed\"] = 0\n",
        "config[\"rho\"] = 95\n",
        "config[\"run_name\"] = \"cmnist_sup\"\n",
        "config[\"exp_root\"] = \"logs\"\n",
        "config[\"reweight_groups\"] = False\n",
        "config[\"reweight_classes\"] = False\n",
        "config[\"seed\"] = 0\n",
        "config[\"num_workers\"] = 2\n",
        "config[\"pin_memory\"] = False\n",
        "config[\"wandb\"] = False\n",
        "config[\"uw_factor\"] = 10\n",
        "config[\"dw_factor\"] = 0.1\n",
        "\n",
        "os.makedirs(f\"logs/{config['exp_root']}\", exist_ok = True)"
      ],
      "metadata": {
        "id": "tVZZ60h7jPHy"
      },
      "id": "tVZZ60h7jPHy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Again, you can launch the training by running the following cells"
      ],
      "metadata": {
        "id": "Lbc8_WfPgZsv"
      },
      "id": "Lbc8_WfPgZsv"
    },
    {
      "cell_type": "code",
      "source": [
        "suptrainer = NaiveSupervisedTrainer(config)\n",
        "suptrainer()"
      ],
      "metadata": {
        "id": "5oY_oG0bjdEK"
      },
      "id": "5oY_oG0bjdEK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The same goes for model evaluation"
      ],
      "metadata": {
        "id": "t7X1d_HeggQd"
      },
      "id": "t7X1d_HeggQd"
    },
    {
      "cell_type": "code",
      "source": [
        "from JTMD.erm_training import evaluate_model\n",
        "\n",
        "_, performance_meter = evaluate_model(\n",
        "    suptrainer.classifier,\n",
        "    suptrainer.test_loader,\n",
        "    suptrainer.num_classes,\n",
        "    suptrainer.num_groups,\n",
        "    suptrainer.criterion,\n",
        "    config[\"epoch\"],\n",
        "    device=suptrainer.device,\n",
        "    wb=None,\n",
        "    prefix=\"test\",\n",
        "    config=config\n",
        ")\n",
        "\n",
        "performance_meter.plot_subgroup_metrics(show=True, fontsize=7, figsize=(8, 5))"
      ],
      "metadata": {
        "id": "ZDwSXakyjl1n"
      },
      "id": "ZDwSXakyjl1n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will turn to the unsupervised debiasing case, where we do not have access to any annotation or prior information on bias.\n",
        "\n",
        "This time, we will ask you to fill in some of the required code for running this method. The configuration parameters are already defined for you in the cell below, while the partial implementation will follow next."
      ],
      "metadata": {
        "id": "scKGQXSMgknG"
      },
      "id": "scKGQXSMgknG"
    },
    {
      "cell_type": "code",
      "source": [
        "config = DotDict()\n",
        "config[\"dataset\"] = \"cmnist\"\n",
        "config[\"arch\"] = \"mlp\"\n",
        "config[\"pretrain\"] = \"none\"\n",
        "config[\"optimizer\"] = \"adam\"\n",
        "config[\"lr\"] = 1e-04\n",
        "config[\"batch_size\"] = 256\n",
        "config[\"epoch\"] = 20\n",
        "config[\"weight_decay\"] = 0.0\n",
        "config[\"amp\"] = False\n",
        "config[\"start_seed\"] = 0\n",
        "config[\"rho\"] = 95\n",
        "config[\"run_name\"] = \"cmnist_lff\"\n",
        "config[\"exp_root\"] = config[\"run_name\"]\n",
        "config[\"reweight_groups\"] = False\n",
        "config[\"reweight_classes\"] = False\n",
        "config[\"seed\"] = 0\n",
        "config[\"num_workers\"] = 2\n",
        "config[\"pin_memory\"] = False\n",
        "config[\"wandb\"] = False\n",
        "\n",
        "os.makedirs(f\"logs/{config['exp_root']}\", exist_ok = True)"
      ],
      "metadata": {
        "id": "B-rOAMWfOvmc"
      },
      "id": "B-rOAMWfOvmc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from JTMD.utils.idx_dataset import IdxDataset\n",
        "from JTMD.utils.EMA_torch_gpu import EMAGPU as EMA\n",
        "from tqdm import tqdm\n",
        "from JTMD.models.criterion import GeneralizedCECriterion\n",
        "from JTMD.models.classifiers import get_classifier\n",
        "from JTMD.methods.base_trainer import BaseTrainer\n",
        "\n",
        "\n",
        "class LfFTrainer(BaseTrainer):\n",
        "    def _method_specific_setups(self):\n",
        "        train_target_attr = self.train_set.get_labels()\n",
        "        self.sample_loss_ema_b = EMA(\n",
        "            torch.LongTensor(train_target_attr), device=self.device, alpha=0.7\n",
        "        )\n",
        "        self.sample_loss_ema_d = EMA(\n",
        "            torch.LongTensor(train_target_attr), device=self.device, alpha=0.7\n",
        "        )\n",
        "\n",
        "    def _modify_train_set(self, train_dataset):\n",
        "        return train_dataset\n",
        "\n",
        "    def _setup_models(self):\n",
        "        super(LfFTrainer, self)._setup_models()\n",
        "        self.bias_discover_net = get_classifier(\n",
        "            arch=self.args.arch,\n",
        "            num_classes=self.num_classes,\n",
        "        ).to(self.device)\n",
        "\n",
        "    def _setup_criterion(self):\n",
        "        self.criterion = nn.CrossEntropyLoss(reduction=\"none\")\n",
        "        self.gce_criterion = GeneralizedCECriterion()\n",
        "\n",
        "    def _setup_optimizers(self):\n",
        "        super(LfFTrainer, self)._setup_optimizers()\n",
        "        args = self.args\n",
        "        match args.optimizer:\n",
        "            case \"sgd\":\n",
        "                self.optimizer_bias_discover_net = torch.optim.SGD(\n",
        "                    self.bias_discover_net.parameters(),\n",
        "                    args.lr,\n",
        "                    momentum=args.momentum,\n",
        "                    weight_decay=args.weight_decay,\n",
        "                )\n",
        "            case \"adamw\":\n",
        "                self.optimizer_bias_discover_net = torch.optim.AdamW(\n",
        "                    self.bias_discover_net.parameters(),\n",
        "                    args.lr,\n",
        "                    weight_decay=args.weight_decay\n",
        "                )\n",
        "            case \"adam\":\n",
        "                self.optimizer_bias_discover_net = torch.optim.Adam(\n",
        "                    self.bias_discover_net.parameters(),\n",
        "                    args.lr,\n",
        "                    weight_decay=args.weight_decay\n",
        "                )\n",
        "            case _:\n",
        "                raise NotImplementedError\n",
        "\n",
        "    def _setup_method_name_and_default_name(self):\n",
        "        args = self.args\n",
        "        args.method = \"lff\"\n",
        "        default_name = f\"{args.method}_{args.dataset}\"\n",
        "        self.default_name = default_name\n",
        "\n",
        "    def train(self):\n",
        "        args = self.args\n",
        "        self.bias_discover_net.train()\n",
        "        self.classifier.train()\n",
        "\n",
        "        total_cls_loss = 0\n",
        "        total_ce_loss = 0\n",
        "        total_gce_loss = 0\n",
        "\n",
        "        pbar = tqdm(self.train_loader, dynamic_ncols=True)\n",
        "        for batch, (dat, labels, idx_data) in enumerate(pbar):\n",
        "            img, target = dat, labels\n",
        "            label = target[0]\n",
        "            group_gt = labels[1]\n",
        "            img = img.to(self.device, non_blocking=True)\n",
        "            label = label.to(self.device, non_blocking=True)\n",
        "            group_gt = group_gt.to(self.device, non_blocking=True)\n",
        "\n",
        "            with torch.amp.autocast(\"cuda\", enabled=args.amp):\n",
        "                spurious_logits = self.bias_discover_net(img)\n",
        "                target_logits = self.classifier(img)\n",
        "                ce_loss = self.criterion(target_logits, label)\n",
        "                gce_loss = self.gce_criterion(spurious_logits, label).mean()\n",
        "\n",
        "            loss_b = self.criterion(spurious_logits, label).detach()\n",
        "            loss_d = ce_loss.detach()\n",
        "\n",
        "            # EMA sample loss\n",
        "            self.sample_loss_ema_b.update(loss_b, idx_data)\n",
        "            self.sample_loss_ema_d.update(loss_d, idx_data)\n",
        "\n",
        "            # class-wise normalize\n",
        "            loss_b = self.sample_loss_ema_b.parameter[idx_data].clone().detach()\n",
        "            loss_d = self.sample_loss_ema_d.parameter[idx_data].clone().detach()\n",
        "\n",
        "            max_loss_b = self.sample_loss_ema_b.max_loss(label)\n",
        "            max_loss_d = self.sample_loss_ema_d.max_loss(label)\n",
        "            loss_b /= max_loss_b\n",
        "            loss_d /= max_loss_d\n",
        "\n",
        "            loss_weight = # Fill here\n",
        "            ce_loss = # Fill here\n",
        "\n",
        "            loss = ce_loss + gce_loss\n",
        "\n",
        "            self.optimizer.zero_grad(set_to_none=True)\n",
        "            self.optimizer_bias_discover_net.zero_grad(set_to_none=True)\n",
        "            self._loss_backward(loss)\n",
        "            self._optimizer_step(self.optimizer)\n",
        "            self._optimizer_step(self.optimizer_bias_discover_net)\n",
        "\n",
        "            self._scaler_update()\n",
        "\n",
        "            total_cls_loss += loss.item()\n",
        "            total_ce_loss += ce_loss.item()\n",
        "            total_gce_loss += gce_loss.item()\n",
        "            avg_cls_loss = total_cls_loss / (batch + 1)\n",
        "            avg_ce_loss = total_ce_loss / (batch + 1)\n",
        "            avg_gce_loss = total_gce_loss / (batch + 1)\n",
        "\n",
        "            pbar.set_description(\n",
        "                \"[{}/{}] cls_loss: {:.3f}, ce: {:.3f}, gce: {:.3f}\".format(\n",
        "                    self.cur_epoch,\n",
        "                    args.epoch,\n",
        "                    avg_cls_loss,\n",
        "                    avg_ce_loss,\n",
        "                    avg_gce_loss,\n",
        "                )\n",
        "            )\n",
        "\n",
        "        log_dict = {\n",
        "            \"loss\": total_cls_loss / len(self.train_loader),\n",
        "            \"ce_loss\": total_ce_loss / len(self.train_loader),\n",
        "            \"gce_loss\": total_gce_loss / len(self.train_loader),\n",
        "        }\n",
        "        self.log_to_wandb(log_dict)\n",
        "\n",
        "    def _state_dict_for_save(self):\n",
        "        state_dict = super(LfFTrainer, self)._state_dict_for_save()\n",
        "        state_dict.update(\n",
        "            {\n",
        "                \"bias_discover_net\": self.bias_discover_net.state_dict(),\n",
        "                \"optimizer_bias_discover_net\": self.optimizer_bias_discover_net.state_dict(),\n",
        "            }\n",
        "        )\n",
        "        return state_dict\n",
        "\n",
        "    def _load_state_dict(self, state_dict):\n",
        "        super(LfFTrainer, self)._load_state_dict(state_dict)\n",
        "        self.bias_discover_net.load_state_dict(state_dict[\"bias_discover_net\"])\n",
        "        self.optimizer_bias_discover_net.load_state_dict(\n",
        "            state_dict[\"optimizer_bias_discover_net\"]\n",
        "        )\n"
      ],
      "metadata": {
        "id": "sIVnJpEoh8Ph"
      },
      "id": "sIVnJpEoh8Ph",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lff_trainer = LfFTrainer(config)\n",
        "lff_trainer()"
      ],
      "metadata": {
        "id": "n_w3_hg2YWzz"
      },
      "id": "n_w3_hg2YWzz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from JTMD.erm_training import evaluate_model\n",
        "\n",
        "_, performance_meter = evaluate_model(\n",
        "    lff_trainer.classifier,\n",
        "    lff_trainer.test_loader,\n",
        "    lff_trainer.num_classes,\n",
        "    lff_trainer.num_groups,\n",
        "    lff_trainer.criterion,\n",
        "    config[\"epoch\"],\n",
        "    device=trainer.device,\n",
        "    wb=None,\n",
        "    prefix=\"test\",\n",
        "    config=config\n",
        ")\n",
        "\n",
        "performance_meter.export_csv()\n",
        "performance_meter.plot_subgroup_metrics(show=True, fontsize=7, figsize=(8, 5))"
      ],
      "metadata": {
        "id": "Pro_WzHgYIyD"
      },
      "id": "Pro_WzHgYIyD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "fd7d7c28",
      "metadata": {
        "id": "fd7d7c28"
      },
      "source": [
        "##### **Second Part: a realistic case with BAR (Biased Action Recognition)**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "120c6c2d",
      "metadata": {
        "id": "120c6c2d"
      },
      "source": [
        "In the second part of this hands-on, we will focus to a more realistic scenario. We will exploit a popular benchmark in model debiasing for image classification, BAR (Biased Action Recognition). Originally introduced in [1], we will be using the renewed version from [3], where bias annotations have been made available, and equipped with two bias severity settings.\n",
        "\n",
        "As we did for CMNIST, we will compare the performance of ERM, a naive supervised debiasing scheme, and an unsupervised method."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from JTMD.datasets.bar import BAR\n",
        "train_set = BAR(\"data\", bias_amount=95, transform=transforms.Compose([transforms.Resize((224, 224)), transforms.ToTensor()]))\n",
        "\n",
        "show_bias_image_grid(train_set, 6, bias_logic=\"bias_is_zero\")"
      ],
      "metadata": {
        "id": "8NQfHyPHbdeW"
      },
      "id": "8NQfHyPHbdeW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = DotDict()\n",
        "config[\"dataset\"] = \"bar\"\n",
        "config[\"arch\"] = \"resnet18\"\n",
        "config[\"pretrain\"] = \"default\"\n",
        "config[\"optimizer\"] = \"adam\"\n",
        "config[\"nesterov\"] = True\n",
        "config[\"momentum\"] = 0.9\n",
        "config[\"lr\"] = 1e-04\n",
        "config[\"batch_size\"] = 64\n",
        "config[\"epoch\"] = 30\n",
        "config[\"weight_decay\"] = 1e-04\n",
        "config[\"amp\"] = True\n",
        "config[\"start_seed\"] = 0\n",
        "config[\"rho\"] = 99\n",
        "config[\"run_name\"] = \"bar_erm\"\n",
        "config[\"exp_root\"] = config[\"run_name\"]\n",
        "config[\"reweight_groups\"] = False\n",
        "config[\"reweight_classes\"] = True\n",
        "config[\"seed\"] = 0\n",
        "config[\"num_workers\"] = 2\n",
        "config[\"pin_memory\"] = False\n",
        "config[\"wandb\"] = False\n",
        "\n",
        "os.makedirs(f\"logs/{config['exp_root']}\", exist_ok = True)"
      ],
      "metadata": {
        "id": "wowce7Ra5Kv_"
      },
      "id": "wowce7Ra5Kv_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = ERMTrainer(config)\n",
        "trainer()"
      ],
      "metadata": {
        "id": "ZZwl_xMr5nAz"
      },
      "id": "ZZwl_xMr5nAz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from JTMD.erm_training import evaluate_model\n",
        "\n",
        "_, performance_meter = evaluate_model(\n",
        "    trainer.classifier,\n",
        "    trainer.test_loader,\n",
        "    trainer.num_classes,\n",
        "    trainer.num_groups,\n",
        "    trainer.criterion,\n",
        "    config[\"epoch\"],\n",
        "    device=trainer.device,\n",
        "    wb=None,\n",
        "    prefix=\"test\",\n",
        "    config=config\n",
        ")\n",
        "\n",
        "performance_meter.plot_subgroup_metrics(show=True, fontsize=12, figsize=(8, 5))"
      ],
      "metadata": {
        "id": "gkgJ9yc_5f6b"
      },
      "id": "gkgJ9yc_5f6b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = DotDict()\n",
        "config[\"dataset\"] = \"bar\"\n",
        "config[\"arch\"] = \"resnet18\"\n",
        "config[\"pretrain\"] = \"default\"\n",
        "config[\"optimizer\"] = \"adam\"\n",
        "config[\"lr\"] = 1e-04\n",
        "config[\"epoch\"] = 30\n",
        "config[\"batch_size\"] = 64\n",
        "config[\"weight_decay\"] = 1e-04\n",
        "config[\"amp\"] = True\n",
        "config[\"start_seed\"] = 0\n",
        "config[\"rho\"] = 99\n",
        "config[\"run_name\"] = \"bar_lff\"\n",
        "config[\"exp_root\"] = config[\"run_name\"]\n",
        "config[\"reweight_groups\"] = False\n",
        "config[\"reweight_classes\"] = True\n",
        "config[\"seed\"] = 0\n",
        "config[\"num_workers\"] = 2\n",
        "config[\"pin_memory\"] = False\n",
        "config[\"wandb\"] = False\n",
        "\n",
        "os.makedirs(f\"logs/{config['exp_root']}\", exist_ok = True)"
      ],
      "metadata": {
        "id": "WjsbGm-VNjzU"
      },
      "id": "WjsbGm-VNjzU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lff_trainer = LfFTrainer(config)\n",
        "lff_trainer()"
      ],
      "metadata": {
        "id": "rgus0YUFNqe5"
      },
      "id": "rgus0YUFNqe5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from JTMD.erm_training import evaluate_model\n",
        "\n",
        "_, performance_meter = evaluate_model(\n",
        "    lff_trainer.classifier,\n",
        "    lff_trainer.test_loader,\n",
        "    lff_trainer.num_classes,\n",
        "    lff_trainer.num_groups,\n",
        "    lff_trainer.criterion,\n",
        "    config[\"epoch\"],\n",
        "    device=lff_trainer.device,\n",
        "    wb=None,\n",
        "    prefix=\"test\",\n",
        "    config=config\n",
        ")\n",
        "\n",
        "performance_meter.plot_subgroup_metrics(show=True, fontsize=8, figsize=(8, 5))"
      ],
      "metadata": {
        "id": "98kX3gy_Nyzo"
      },
      "id": "98kX3gy_Nyzo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = DotDict()\n",
        "config[\"dataset\"] = \"bar\"\n",
        "config[\"arch\"] = \"resnet18\"\n",
        "config[\"pretrain\"] = \"default\"\n",
        "config[\"optimizer\"] = \"adam\"\n",
        "config[\"lr\"] = 1e-04\n",
        "config[\"batch_size\"] = 64\n",
        "config[\"epoch\"] = 20\n",
        "config[\"weight_decay\"] = 0.0\n",
        "config[\"amp\"] = False\n",
        "config[\"start_seed\"] = 0\n",
        "config[\"rho\"] = 95\n",
        "config[\"run_name\"] = \"bar_sup\"\n",
        "config[\"exp_root\"] = config[\"run_name\"]\n",
        "config[\"reweight_groups\"] = False\n",
        "config[\"reweight_classes\"] = False\n",
        "config[\"seed\"] = 0\n",
        "config[\"num_workers\"] = 2\n",
        "config[\"pin_memory\"] = False\n",
        "config[\"wandb\"] = False\n",
        "config[\"uw_factor\"] = 10\n",
        "config[\"dw_factor\"] = 0.1\n",
        "\n",
        "os.makedirs(f\"logs/{config['exp_root']}\", exist_ok = True)"
      ],
      "metadata": {
        "id": "6gozsJT9GMoT"
      },
      "execution_count": null,
      "outputs": [],
      "id": "6gozsJT9GMoT"
    },
    {
      "cell_type": "code",
      "source": [
        "suptrainer = NaiveSupervisedTrainer(config)\n",
        "suptrainer()"
      ],
      "metadata": {
        "id": "0oOkdhQtGMoV"
      },
      "execution_count": null,
      "outputs": [],
      "id": "0oOkdhQtGMoV"
    },
    {
      "cell_type": "code",
      "source": [
        "from JTMD.erm_training import evaluate_model\n",
        "\n",
        "_, performance_meter = evaluate_model(\n",
        "    suptrainer.classifier,\n",
        "    suptrainer.test_loader,\n",
        "    suptrainer.num_classes,\n",
        "    suptrainer.num_groups,\n",
        "    suptrainer.criterion,\n",
        "    config[\"epoch\"],\n",
        "    device=suptrainer.device,\n",
        "    wb=None,\n",
        "    prefix=\"test\",\n",
        "    config=config\n",
        ")\n",
        "\n",
        "performance_meter.export_csv()\n",
        "performance_meter.plot_subgroup_metrics(show=True, fontsize=7, figsize=(8, 5))"
      ],
      "metadata": {
        "id": "pIo3tMeBGMoW"
      },
      "execution_count": null,
      "outputs": [],
      "id": "pIo3tMeBGMoW"
    },
    {
      "cell_type": "markdown",
      "id": "9b8cf85b",
      "metadata": {
        "id": "9b8cf85b"
      },
      "source": [
        "### **References**\n",
        "\n",
        "[1] Li, Zhiheng, et al. \"A whac-a-mole dilemma: Shortcuts come in multiples where mitigating one amplifies others.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023.  \n",
        "[2] Nam, Junhyun, et al. \"Learning from failure: De-biasing classifier from biased classifier.\" Advances in Neural Information Processing Systems 33 (2020): 20673-20684."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}